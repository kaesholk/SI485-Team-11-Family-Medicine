{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import necessary libraries\n",
    "%pip install numpy pandas requests openpyxl\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import string\n",
    "import re\n",
    "\n",
    "# API credentials\n",
    "API_KEY = 'ada006c4a6c245fb12af2a0edd84d12d'\n",
    "INST_TOKEN = 'daeb14a8b7d45dd0d76921ce1fd3e6a5'\n",
    "\n",
    "# Load Excel data\n",
    "faculty = pd.read_excel(\"ORCID_Faculty.xlsx\")\n",
    "\n",
    "# Clean and format faculty data\n",
    "faculty['SCOPUS ID'] = faculty['SCOPUS ID'].astype(str).str.replace('.0', '', regex=False)\n",
    "faculty['LAST NAME'] = faculty['LAST NAME'].apply(string.capwords)\n",
    "faculty['FIRST, MIDDLE NAME(S)'] = faculty['FIRST, MIDDLE NAME(S)'].apply(string.capwords)\n",
    "faculty['Name'] = faculty['FIRST, MIDDLE NAME(S)'] + ' ' + faculty['LAST NAME']\n",
    "\n",
    "def get_abstract_and_keywords(api_key, scopus_id):\n",
    "    \"\"\"\n",
    "    Fetch the abstract and author keywords for a given Scopus ID.\n",
    "    \"\"\"\n",
    "    url = f'http://api.elsevier.com/content/abstract/scopus_id/{scopus_id}'\n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'X-ELS-APIKey': api_key,\n",
    "        'X-ELS-Insttoken': INST_TOKEN\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        abstract = data.get(\"abstracts-retrieval-response\", {}).get(\"item\", {}).get(\"bibrecord\", {}).get(\"head\", {}).get(\"abstracts\", None)\n",
    "\n",
    "        keywords_data = data.get(\"abstracts-retrieval-response\", {}).get(\"item\", {}).get(\"bibrecord\", {}).get(\"head\", {}).get(\"citation-info\", {}).get(\"author-keywords\", {}).get(\"author-keyword\", [])\n",
    "\n",
    "        if isinstance(keywords_data, list):\n",
    "            keywords = \"; \".join([kw.get(\"$\", \"\") for kw in keywords_data])\n",
    "        elif isinstance(keywords_data, dict):\n",
    "            keywords = keywords_data.get(\"$\", \"\")\n",
    "        else:\n",
    "            keywords = \"\"\n",
    "\n",
    "        return abstract, keywords\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def get_publications(api_key, author_id, full_name, orcid_id):\n",
    "    \"\"\"\n",
    "    Fetch all publications associated with a given author ID.\n",
    "    Returns a DataFrame of publication details.\n",
    "    \"\"\"\n",
    "    query = f'AU-ID%28{author_id}%29'\n",
    "    url = f'https://api.elsevier.com/content/search/scopus?query={query}'\n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'X-ELS-APIKey': api_key,\n",
    "        'X-ELS-Insttoken': INST_TOKEN\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        entries = data.get('search-results', {}).get('entry', [])\n",
    "        if not entries:\n",
    "            print(\"No publications found.\")\n",
    "            return []\n",
    "\n",
    "        publications = []\n",
    "        for pub in entries:\n",
    "            title = pub.get('dc:title', 'N/A')\n",
    "            affiliation = pub.get('affiliation', [{}])[0].get('affilname', 'N/A')\n",
    "            journal = pub.get('prism:publicationName', 'N/A')\n",
    "            doi = pub.get('prism:doi', 'N/A')\n",
    "            year = pub.get('prism:coverDate', 'N/A')[:4]\n",
    "            pub_type = pub.get('subtypeDescription', 'N/A')\n",
    "\n",
    "            scopus_id = pub.get('dc:identifier', 'N/A').split(':')[1] if pub.get('dc:identifier') else None\n",
    "            abstract, keywords = get_abstract_and_keywords(api_key, scopus_id) if scopus_id else ('N/A', 'N/A')\n",
    "\n",
    "            # Avoid duplicate titles\n",
    "            if title not in [p['Title'] for p in publications]:\n",
    "                publications.append({\n",
    "                    'Name': full_name,\n",
    "                    'ORCID': orcid_id,\n",
    "                    'Scopus ID': author_id,\n",
    "                    'Title': title,\n",
    "                    'Article Affiliation': affiliation,\n",
    "                    'Journal': journal,\n",
    "                    'Year': year,\n",
    "                    'Type': pub_type,\n",
    "                    'DOI': doi,\n",
    "                    'Keywords': keywords,\n",
    "                    'Abstract': abstract\n",
    "                })\n",
    "\n",
    "        return pd.DataFrame(publications)\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return []\n",
    "\n",
    "def populate_data_frame(api_key, author_id, full_name, orcid_id):\n",
    "    \"\"\"\n",
    "    Wrapper function to return publication data if author ID exists.\n",
    "    \"\"\"\n",
    "    if author_id:\n",
    "        return get_publications(api_key, author_id, full_name, orcid_id)\n",
    "    return pd.DataFrame([])\n",
    "\n",
    "def fix_punctuation(text):\n",
    "    \"\"\"\n",
    "    Replaces encoded punctuation characters and strips HTML tags.\n",
    "    \"\"\"\n",
    "    replacements = {\n",
    "        \"‚Äô\": \"’\",\n",
    "        \"‚Äú\": \"“\",\n",
    "        \"‚Äù\": \"”\"\n",
    "    }\n",
    "    for old, new in replacements.items():\n",
    "        text = text.replace(old, new)\n",
    "    return re.sub(r\"<sup>(\\d+)</sup>\", r\"\\1\", text)\n",
    "\n",
    "# Initialize final DataFrame\n",
    "df = pd.DataFrame(columns=[\n",
    "    'Name', 'ORCID', 'Scopus ID', 'Title', 'Article Affiliation',\n",
    "    'Journal', 'Year', 'Type', 'DOI', 'Keywords', 'Abstract'\n",
    "])\n",
    "\n",
    "# Loop through faculty and collect publication data\n",
    "for _, row in faculty.iterrows():\n",
    "    publications = populate_data_frame(API_KEY, row[\"SCOPUS ID\"], row[\"Name\"], row[\"ORCID ID#\"])\n",
    "    df = pd.concat([df, publications], ignore_index=True)\n",
    "\n",
    "# Cleaning: drop rows with missing Scopus ID\n",
    "df = df.dropna(subset=['Scopus ID'])\n",
    "\n",
    "# Remove unwanted punctuation in Abstracts\n",
    "df['Abstract'] = df['Abstract'].apply(lambda x: re.sub(r\"^[^\\w\\d]+\", \"\", str(x)))\n",
    "\n",
    "# Clean up Title formatting\n",
    "df['Title'] = df['Title'].apply(fix_punctuation)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('scopus_publications_2_4.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
